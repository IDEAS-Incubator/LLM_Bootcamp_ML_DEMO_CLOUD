{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Linear Regression Demo\n",
        "\n",
        "Run the colab Demo :  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1e2u6U6BZrBBbm2LyXIyNNvgmvtxjAuEh?usp=sharing)"
      ],
      "metadata": {
        "id": "NikKju1TB4Ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Spark in Colab"
      ],
      "metadata": {
        "id": "t77X_r1nCM2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java, Spark 3.3.2 and py4j\n",
        "!apt-get install openjdk-11-jdk -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n"
      ],
      "metadata": {
        "id": "09NtauhsA8pv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n"
      ],
      "metadata": {
        "id": "PkWTQdDTBRfi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at7v93rjAUWz",
        "outputId": "9cc26ac8-714d-4980-ff44-6c9305492a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session started successfully!\n"
          ]
        }
      ],
      "source": [
        "#  Initialize Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Colab Spark MLlib Setup\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session started successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Load the Dataset"
      ],
      "metadata": {
        "id": "E2WdTq5ZCV1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset (features like population, rooms, income, etc.)\n",
        "!wget -q https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv -O housing.csv\n"
      ],
      "metadata": {
        "id": "KE8lX-T3CT--"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = spark.read.csv(\"housing.csv\", header=True, inferSchema=True)\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEyLyU9XCac6",
        "outputId": "468c67e7-5521-411d-ad08-e464fe5d333d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
            "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
            "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
            "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "jZCAFJcGDUSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing data\n",
        "df = df.dropna()\n",
        "\n",
        "# Assemble features into a single vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"housing_median_age\", \"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "assembled_df = assembler.transform(df).select(\"features\", \"median_house_value\")\n",
        "assembled_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK0mg7irDWk2",
        "outputId": "3fa37d02-b589-4135-ae6f-ed847595535e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|            features|median_house_value|\n",
            "+--------------------+------------------+\n",
            "|[41.0,880.0,129.0...|          452600.0|\n",
            "|[21.0,7099.0,1106...|          358500.0|\n",
            "|[52.0,1467.0,190....|          352100.0|\n",
            "|[52.0,1274.0,235....|          341300.0|\n",
            "|[52.0,1627.0,280....|          342200.0|\n",
            "+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "-6AatMOoC0mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = assembled_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train model\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n",
        "model = lr.fit(train_data)\n",
        "\n",
        "print(\"Model trained.\")\n"
      ],
      "metadata": {
        "id": "KHf-iqx7CwG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429c5837-ba76-4b5d-d6d9-d864a697024d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "WeeH_GPNC7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"features\", \"median_house_value\", \"prediction\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KW_HDnxC8uJ",
        "outputId": "5719f342-af41-4da5-c70b-35f7fb876ffc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------------------+\n",
            "|            features|median_house_value|        prediction|\n",
            "+--------------------+------------------+------------------+\n",
            "|[1.0,2062.0,343.0...|          191300.0|204606.20679266436|\n",
            "|[2.0,200.0,20.0,2...|          350000.0| 676768.5676170461|\n",
            "|[2.0,337.0,55.0,1...|          164800.0|108236.42353609539|\n",
            "|[2.0,790.0,135.0,...|          166500.0|202867.57818092796|\n",
            "|[2.0,1658.0,290.0...|          136700.0| 208147.5386566134|\n",
            "+--------------------+------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "ldmLDtd2DrZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "training_summary = model.summary\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"RMSE (Root Mean Squared Error): {training_summary.rootMeanSquaredError:.2f}\")\n",
        "print(f\"MAE (Mean Absolute Error)     : {training_summary.meanAbsoluteError:.2f}\")\n",
        "print(f\"R² (R-squared)                : {training_summary.r2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y20vGYcgDuGq",
        "outputId": "11f7900c-b3e8-4e70-902c-0dd5d5cae960"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "RMSE (Root Mean Squared Error): 75824.69\n",
            "MAE (Mean Absolute Error)     : 55871.86\n",
            "R² (R-squared)                : 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zWtp7xZfDw4Z"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}