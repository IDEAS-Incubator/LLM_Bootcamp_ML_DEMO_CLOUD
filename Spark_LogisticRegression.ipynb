{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark LogisticRegression Demo :\n",
        "\n",
        "Run the colab Demo :  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EVPji_9wCPQizaNF-N9fSfyRoI9UpgH6?usp=sharing)"
      ],
      "metadata": {
        "id": "71H0pUlkCE4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Spark in Colab"
      ],
      "metadata": {
        "id": "t77X_r1nCM2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java, Spark 3.3.2 and py4j\n",
        "!apt-get install openjdk-11-jdk -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n"
      ],
      "metadata": {
        "id": "09NtauhsA8pv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n"
      ],
      "metadata": {
        "id": "PkWTQdDTBRfi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at7v93rjAUWz",
        "outputId": "c69a3aaf-96e4-460f-9e99-7f6c1b106d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session started successfully!\n"
          ]
        }
      ],
      "source": [
        "#  Initialize Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Colab Spark MLlib Setup\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session started successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Load the Iris Dataset"
      ],
      "metadata": {
        "id": "E2WdTq5ZCV1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Iris dataset\n",
        "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -O iris.csv\n"
      ],
      "metadata": {
        "id": "KE8lX-T3CT--"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load into Spark DataFrame\n",
        "df = spark.read.csv(\"iris.csv\", inferSchema=True, header=False)\n",
        "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"label\"]\n",
        "df = df.toDF(*columns)\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEyLyU9XCac6",
        "outputId": "6169a0bc-2521-4719-981b-367bfef88f3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-----------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|      label|\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
            "+------------+-----------+------------+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data for MLlib\n"
      ],
      "metadata": {
        "id": "bJML8A7sCgZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "\n",
        "# Convert labels to numeric\n",
        "indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Combine features into a single vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df = assembler.transform(df).select(\"features\", \"label_index\")\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhVIT-y_Cc5S",
        "outputId": "4cc08a65-5a4e-4878-f9e8-b439a63cb327"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+\n",
            "|         features|label_index|\n",
            "+-----------------+-----------+\n",
            "|[5.1,3.5,1.4,0.2]|        0.0|\n",
            "|[4.9,3.0,1.4,0.2]|        0.0|\n",
            "|[4.7,3.2,1.3,0.2]|        0.0|\n",
            "|[4.6,3.1,1.5,0.2]|        0.0|\n",
            "|[5.0,3.6,1.4,0.2]|        0.0|\n",
            "+-----------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Test Split + Train Model"
      ],
      "metadata": {
        "id": "-6AatMOoC0mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_data, test_data = df.randomSplit([0.7, 0.3], seed=123)\n",
        "\n",
        "# Train logistic regression model\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(labelCol=\"label_index\", featuresCol=\"features\", maxIter=10)\n",
        "model = lr.fit(train_data)\n"
      ],
      "metadata": {
        "id": "KHf-iqx7CwG1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions & Evaluate"
      ],
      "metadata": {
        "id": "WeeH_GPNC7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions & Evaluate\n",
        "\n",
        "# Predict on test data\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"features\", \"label_index\", \"prediction\", \"probability\").show(5)\n",
        "\n",
        "# Import evaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Initialize evaluators\n",
        "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_evaluator.evaluate(predictions)\n",
        "precision = precision_evaluator.evaluate(predictions)\n",
        "recall = recall_evaluator.evaluate(predictions)\n",
        "f1_score = f1_evaluator.evaluate(predictions)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n Evaluation Metrics:\")\n",
        "print(f\" Accuracy  : {accuracy:.2f}\")\n",
        "print(f\" Precision : {precision:.2f}\")\n",
        "print(f\" Recall    : {recall:.2f}\")\n",
        "print(f\" F1 Score  : {f1_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KW_HDnxC8uJ",
        "outputId": "8817bdbb-4e12-44a3-8ea2-5572f5a6ff95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+----------+--------------------+\n",
            "|         features|label_index|prediction|         probability|\n",
            "+-----------------+-----------+----------+--------------------+\n",
            "|[4.4,3.0,1.3,0.2]|        0.0|       0.0|[0.99997707075701...|\n",
            "|[4.6,3.2,1.4,0.2]|        0.0|       0.0|[0.99997157586396...|\n",
            "|[4.7,3.2,1.3,0.2]|        0.0|       0.0|[0.99995112558622...|\n",
            "|[4.8,3.0,1.4,0.3]|        0.0|       0.0|[0.99913046469204...|\n",
            "|[4.8,3.1,1.6,0.2]|        0.0|       0.0|[0.99959022777438...|\n",
            "+-----------------+-----------+----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            " Evaluation Metrics:\n",
            " Accuracy  : 0.95\n",
            " Precision : 0.96\n",
            " Recall    : 0.95\n",
            " F1 Score  : 0.95\n"
          ]
        }
      ]
    }
  ]
}