{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RNN DEMO"
      ],
      "metadata": {
        "id": "HpOsICoD1lMC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_dLykmqhzdZ9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOAD DATASET"
      ],
      "metadata": {
        "id": "FgVxuM5D1n6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Download IMDB dataset\n",
        "print(\"Loading dataset...\")\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz88yaVI0oLH",
        "outputId": "32829c61-47fa-4eb2-e006-8901728992c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get word index mapping\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Create a reverse mapping to decode the reviews\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "decode_review = lambda review: ' '.join([reverse_word_index.get(i - 3, '?') for i in review])\n",
        "\n"
      ],
      "metadata": {
        "id": "K7XKz0Xv02zv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sample review\n",
        "print(\"\\nSample review:\")\n",
        "print(decode_review(x_train[0]))\n",
        "print(f\"Label: {'Positive' if y_train[0] == 1 else 'Negative'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_iG8SMM09Xj",
        "outputId": "da9f1ea0-371d-4822-86d3-584d04674415"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample review:\n",
            "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Label: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "vocab_size = 10000\n",
        "max_length = 250\n",
        "embedding_dim = 100\n",
        "rnn_units = 128\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "# Pad sequences\n",
        "print(\"\\nPreparing data...\")\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Print data shapes\n",
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsTrubD0bqw",
        "outputId": "740e0895-012a-495b-b182-04e9963507c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparing data...\n",
            "Training data shape: (25000, 250)\n",
            "Test data shape: (25000, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BUILD MODEL"
      ],
      "metadata": {
        "id": "uqJf7l6y18Ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create validation split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "print(f\"Validation data shape: {x_val.shape}\")\n",
        "\n",
        "# Build the RNN model\n",
        "print(\"\\nBuilding RNN model...\")\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "    BatchNormalization(),\n",
        "    SimpleRNN(rnn_units, return_sequences=True,\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              recurrent_initializer='orthogonal'),\n",
        "    BatchNormalization(),\n",
        "    SimpleRNN(rnn_units//2,\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              recurrent_initializer='orthogonal'),\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu', kernel_initializer='he_normal'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AsuxyV61J6h",
        "outputId": "1997f4b9-6650-49eb-ac24-a3ebe3e22e0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation data shape: (5000, 250)\n",
            "\n",
            "Building RNN model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with class weights\n",
        "total_samples = len(y_train)\n",
        "pos_samples = np.sum(y_train)\n",
        "neg_samples = total_samples - pos_samples\n",
        "class_weight = {\n",
        "    0: total_samples / (2 * neg_samples),\n",
        "    1: total_samples / (2 * pos_samples)\n",
        "}\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "HCidCD6m1Kqm",
        "outputId": "139e484e-aff0-456d-e809-9b14d33f406f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        'best_rnn_model.keras',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nTraining the model...\")\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNdIWgUC1NRr",
        "outputId": "db32ccc4-4ce1-449e-9337-eca9364ec30d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.5098 - loss: 0.8287\n",
            "Epoch 1: val_accuracy improved from -inf to 0.54740, saving model to best_rnn_model.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 265ms/step - accuracy: 0.5098 - loss: 0.8285 - val_accuracy: 0.5474 - val_loss: 0.6851\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.6363 - loss: 0.6300\n",
            "Epoch 2: val_accuracy improved from 0.54740 to 0.62600, saving model to best_rnn_model.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 260ms/step - accuracy: 0.6364 - loss: 0.6299 - val_accuracy: 0.6260 - val_loss: 0.6347\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.7100 - loss: 0.5646\n",
            "Epoch 3: val_accuracy did not improve from 0.62600\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 265ms/step - accuracy: 0.7100 - loss: 0.5646 - val_accuracy: 0.5832 - val_loss: 0.6668\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.7635 - loss: 0.5019\n",
            "Epoch 4: val_accuracy did not improve from 0.62600\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 262ms/step - accuracy: 0.7635 - loss: 0.5019 - val_accuracy: 0.5690 - val_loss: 0.8709\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.7875 - loss: 0.4643\n",
            "Epoch 5: val_accuracy did not improve from 0.62600\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 257ms/step - accuracy: 0.7875 - loss: 0.4643 - val_accuracy: 0.5612 - val_loss: 0.6870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print training history\n",
        "print(\"\\nTraining History:\")\n",
        "for epoch in range(len(history.history['loss'])):  # Use actual number of completed epochs\n",
        "    print(f\"Epoch {epoch+1}/{len(history.history['loss'])}:\")\n",
        "    print(f\"  Training Loss: {history.history['loss'][epoch]:.4f}\")\n",
        "    print(f\"  Training Accuracy: {history.history['accuracy'][epoch]:.4f}\")\n",
        "    print(f\"  Validation Loss: {history.history['val_loss'][epoch]:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {history.history['val_accuracy'][epoch]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZEy9S2P1QMn",
        "outputId": "84ebad27-a92c-4e30-cb00-18f549c32beb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training History:\n",
            "Epoch 1/5:\n",
            "  Training Loss: 0.7567\n",
            "  Training Accuracy: 0.5218\n",
            "  Validation Loss: 0.6851\n",
            "  Validation Accuracy: 0.5474\n",
            "Epoch 2/5:\n",
            "  Training Loss: 0.6121\n",
            "  Training Accuracy: 0.6618\n",
            "  Validation Loss: 0.6347\n",
            "  Validation Accuracy: 0.6260\n",
            "Epoch 3/5:\n",
            "  Training Loss: 0.5589\n",
            "  Training Accuracy: 0.7173\n",
            "  Validation Loss: 0.6668\n",
            "  Validation Accuracy: 0.5832\n",
            "Epoch 4/5:\n",
            "  Training Loss: 0.4875\n",
            "  Training Accuracy: 0.7727\n",
            "  Validation Loss: 0.8709\n",
            "  Validation Accuracy: 0.5690\n",
            "Epoch 5/5:\n",
            "  Training Loss: 0.4588\n",
            "  Training Accuracy: 0.7912\n",
            "  Validation Loss: 0.6870\n",
            "  Validation Accuracy: 0.5612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TESTING ON TEST SET\")\n",
        "print(\"=\"*50)\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "# Generate predictions on test set\n",
        "print(\"\\nGenerating predictions on test set...\")\n",
        "y_pred_prob = model.predict(x_test, verbose=1)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calculate detailed metrics on test set\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djsiqnqe1V7a",
        "outputId": "f1ea6a4d-ef41-4fcf-9834-ffa8cb95d9f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "TESTING ON TEST SET\n",
            "==================================================\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - accuracy: 0.5759 - loss: 0.6741\n",
            "Test accuracy: 0.5761\n",
            "Test loss: 0.6742\n",
            "\n",
            "Generating predictions on test set...\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.59      0.58     12500\n",
            "           1       0.58      0.57      0.57     12500\n",
            "\n",
            "    accuracy                           0.58     25000\n",
            "   macro avg       0.58      0.58      0.58     25000\n",
            "weighted avg       0.58      0.58      0.58     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print confusion matrix for test set\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix (Test Set):\")\n",
        "print(f\"                | Predicted Negative | Predicted Positive |\")\n",
        "print(f\"Actual Negative | {cm[0][0]:<18} | {cm[0][1]:<18} |\")\n",
        "print(f\"Actual Positive | {cm[1][0]:<18} | {cm[1][1]:<18} |\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvVd7HE51WyW",
        "outputId": "c7c7c9fc-630c-4006-9748-9459116dc597"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix (Test Set):\n",
            "                | Predicted Negative | Predicted Positive |\n",
            "Actual Negative | 7318               | 5182               |\n",
            "Actual Positive | 5416               | 7084               |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample test set predictions\n",
        "print(\"\\nSample Test Set Predictions:\")\n",
        "for i in range(5):\n",
        "    review = decode_review(x_test[i])\n",
        "    prediction = \"Positive\" if y_pred[i] == 1 else \"Negative\"\n",
        "    actual = \"Positive\" if y_test[i] == 1 else \"Negative\"\n",
        "    confidence = y_pred_prob[i][0]\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Review: {review[:100]}...\")\n",
        "    print(f\"Predicted: {prediction} (confidence: {confidence:.4f}), Actual: {actual}\")\n",
        "\n",
        "# Calculate additional metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
        "precision = report_dict['weighted avg']['precision']\n",
        "recall = report_dict['weighted avg']['recall']\n",
        "f1 = report_dict['weighted avg']['f1-score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6FVjOB61eDl",
        "outputId": "9e31506b-372e-4ba4-81f0-01c17d957e37"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Test Set Predictions:\n",
            "--------------------------------------------------------------------------------\n",
            "Review: ? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the ...\n",
            "Predicted: Negative (confidence: 0.1314), Actual: Negative\n",
            "--------------------------------------------------------------------------------\n",
            "Review: ? this film requires a lot of patience because it focuses on mood and character development the plot...\n",
            "Predicted: Negative (confidence: 0.4092), Actual: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "Review: ? many animation buffs consider ? ? the great forgotten genius of one special branch of the art pupp...\n",
            "Predicted: Negative (confidence: 0.4783), Actual: Positive\n",
            "--------------------------------------------------------------------------------\n",
            "Review: ? i generally love this type of movie however this time i found myself wanting to kick the screen si...\n",
            "Predicted: Positive (confidence: 0.7176), Actual: Negative\n",
            "--------------------------------------------------------------------------------\n",
            "Review: ? like some other people wrote i'm a die hard mario fan and i loved this game br br this game starts...\n",
            "Predicted: Negative (confidence: 0.2549), Actual: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of test results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TEST SET SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total test samples: {len(y_test)}\")\n",
        "print(f\"Correct predictions: {sum(y_pred == y_test)}\")\n",
        "print(f\"Incorrect predictions: {sum(y_pred != y_test)}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Class-specific metrics\n",
        "print(\"\\nClass-specific metrics:\")\n",
        "print(\"Negative reviews:\")\n",
        "print(f\"  Precision: {report_dict['0']['precision']:.4f}\")\n",
        "print(f\"  Recall: {report_dict['0']['recall']:.4f}\")\n",
        "print(f\"  F1-Score: {report_dict['0']['f1-score']:.4f}\")\n",
        "\n",
        "print(\"Positive reviews:\")\n",
        "print(f\"  Precision: {report_dict['1']['precision']:.4f}\")\n",
        "print(f\"  Recall: {report_dict['1']['recall']:.4f}\")\n",
        "print(f\"  F1-Score: {report_dict['1']['f1-score']:.4f}\")\n",
        "\n",
        "print(\"\\nDone!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_slMXUZU1fD6",
        "outputId": "2ea4bb2a-9588-496f-8c37-d4bb82b6b160"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "TEST SET SUMMARY\n",
            "==================================================\n",
            "Total test samples: 25000\n",
            "Correct predictions: 14402\n",
            "Incorrect predictions: 10598\n",
            "Accuracy: 0.5761\n",
            "Precision: 0.5761\n",
            "Recall: 0.5761\n",
            "F1-Score: 0.5760\n",
            "\n",
            "Class-specific metrics:\n",
            "Negative reviews:\n",
            "  Precision: 0.5747\n",
            "  Recall: 0.5854\n",
            "  F1-Score: 0.5800\n",
            "Positive reviews:\n",
            "  Precision: 0.5775\n",
            "  Recall: 0.5667\n",
            "  F1-Score: 0.5721\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}